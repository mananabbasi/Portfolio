# 🎯 **Data Scientist Portfolio**  
🌟 Welcome to my **Data Scientist Portfolio** repository! 🚀  
This is a curated collection of my work, showcasing my expertise in **data analysis, machine learning, and visualization**.  
Each project reflects my ability to extract meaningful insights, develop predictive models, and present data-driven solutions effectively.

---

## 📌 **Table of Contents**  
- [🌟 About Me](#about-me)  
- [🚀 Projects](#projects)  
- [🛠 Skills](#skills)  
- [⚙ Tools & Technologies](#tools--technologies)  
- [💼 Work Experience](#work-experience)  
- [🎓 Education](#education)  
- [🎯 Activities](#activities)  
- [🔧 How to Use This Repository](#how-to-use-this-repository)  
- [📞 Contact](#contact)  

---

## 🌟 **About Me**  
I am a **data scientist** with a passion for solving complex problems using data-driven approaches.  
With a strong foundation in **statistics**, **machine learning**, and **data visualization**, I specialize in transforming raw data into actionable insights.

### 📊 **Key Expertise:**  
- ✅ **Data Wrangling & Cleaning**  
- ✅ **Exploratory Data Analysis (EDA)**  
- ✅ **Machine Learning & Predictive Modeling**  
- ✅ **Statistical Analysis & Hypothesis Testing**  
- ✅ **Data Visualization & Storytelling**  

---

## 🚀 **Projects**

### 🔹 **1. Developed Databases from Scratch using Microsoft SQL Server** _(Jan 2024 - Apr 2024)_  
**Objective:**  
To design and implement a scalable and efficient relational database system for managing structured data, ensuring optimal performance and data integrity.

**Process:**
- Designed a normalized database schema to eliminate redundancy and ensure data consistency.
- Created tables, relationships, and constraints using T-SQL.
- Optimized queries and implemented indexing strategies to improve query performance.
- Developed stored procedures and triggers for automating repetitive tasks and enforcing business rules.

**Outcome:**  
A fully functional relational database capable of handling large datasets with efficient query execution and scalability for future growth.

**Tools Used:**
- Microsoft SQL Server  
- T-SQL  

---

### 🔹 **2. Conducted Statistical Analysis & Advanced Statistics using R** _(Sep 2024 - Dec 2025)_  
**Objective:**  
To perform in-depth statistical analysis on datasets to derive actionable insights and support data-driven decision-making.

**Process:**
- Conducted hypothesis testing to validate assumptions and draw conclusions.
- Performed regression analysis to identify relationships between variables.
- Applied ANOVA to compare means across multiple groups.
- Visualized statistical insights using ggplot2 for clear and interpretable data representation.

**Outcome:**  
Comprehensive statistical reports and visualizations that provided valuable insights into the dataset, enabling stakeholders to make informed decisions.

**Tools Used:**
- R  
- ggplot2, dplyr  

---

### 🔹 **3. Built Time Series Forecasting Models in R** _(Nov 2024 - Dec 2024)_  
**Objective:**  
To develop predictive models for time series data to forecast future trends and patterns.

**Process:**
- Analyzed historical data to identify seasonal trends and patterns.
- Built ARIMA, SARIMA, and Exponential Smoothing models to predict future values.
- Evaluated model performance using metrics like RMSE and MAE.
- Visualized forecasts and compared them with actual data for validation.

**Outcome:**  
Accurate time series forecasting models that provided reliable predictions for future trends, aiding in strategic planning and decision-making.

**Tools Used:**
- R  
- forecast, tsibble  

---

### 🔹 **4. Designed Power BI Dashboards for Real-Time Insights** _(Jan 2024 - Current)_  
**Objective:**  
To create interactive and dynamic dashboards for real-time monitoring of key performance indicators (KPIs).

**Process:**
- Integrated multiple data sources (e.g., SQL databases, Excel files) into Power BI.
- Designed visually appealing and user-friendly dashboards with interactive elements like slicers and filters.
- Used DAX (Data Analysis Expressions) to create calculated columns and measures for advanced analytics.
- Ensured real-time data updates for accurate and timely reporting.

**Outcome:**  
Interactive dashboards that provided stakeholders with real-time insights into business performance, enabling data-driven decision-making.

**Tools Used:**
- Power BI  
- DAX, SQL  

---

### 🔹 **5. Developed Classification & Clustering Models in Python** _(Sep 2024 - Current)_  
**Objective:**  
To build machine learning models for classification and clustering tasks to uncover patterns and make predictions.

**Process:**
- Preprocessed and cleaned data to ensure quality and consistency.
- Built classification models like Logistic Regression and Random Forest to predict categorical outcomes.
- Implemented clustering algorithms like K-Means and DBSCAN to group similar data points.
- Evaluated model performance using metrics like accuracy, precision, recall, and silhouette score.

**Outcome:**  
Robust machine learning models that provided accurate predictions and insights into data patterns, supporting business decisions.

**Tools Used:**
- Python  
- Scikit-learn, Pandas, Matplotlib  

---

### 🔹 **6. Executed PySpark Projects on Databricks Using RDDs & DataFrames** _(Jan 2024 - Current)_  
**Objective:**  
To process and analyze large-scale datasets efficiently using PySpark on the Databricks platform.

**Process:**
- Used PySpark RDDs (Resilient Distributed Datasets) for distributed data processing.
- Performed data transformations and aggregations using Spark SQL and DataFrames.
- Optimized data pipelines for performance and scalability.
- Visualized processed data to derive insights and support decision-making.

**Outcome:**  
Scalable and efficient data processing pipelines capable of handling large datasets, enabling faster and more accurate data analysis.

**Tools Used:**
- PySpark  
- Databricks, Apache Spark

---

## **Summary**  
These projects demonstrate a strong foundation in **database design**, **statistical analysis**, **machine learning**, and **big data processing**. Each project was tailored to solve real-world problems, leveraging the appropriate tools and methodologies to deliver actionable insights and scalable solutions.

Let me know if you'd like further details or code snippets for any of these projects!

---

## 🛠 **Skills**  
- ✅ **Programming:** Python, R, SQL  
- ✅ **Machine Learning:** Regression, Classification, Clustering, Deep Learning  
- ✅ **Data Analysis:** EDA, A/B Testing, Hypothesis Testing  
- ✅ **Visualization:** Power BI, Tableau, Matplotlib, Seaborn, Plotly  
- ✅ **Big Data & Cloud:** Spark, Hadoop, AWS, Azure, GCP  
- ✅ **Deployment & Version Control:** Flask, Docker, Git  

---

## ⚙ **Tools & Technologies**  
- 💡 **Programming:** Python, R, SQL  
- 💡 **Libraries:** Pandas, NumPy, Scikit-learn, TensorFlow, PyTorch  
- 💡 **Databases:** MySQL, PostgreSQL, MongoDB  
- 💡 **Cloud Platforms:** AWS, Azure, GCP  
- 💡 **Visualization:** Power BI, Tableau, Matplotlib, Seaborn  
- 💡 **Development Tools:** Jupyter Notebook, VS Code, Docker, Git  

---

## 💼 **Work Experience**  

### 📊 **Data Visualization Analyst (Part-Time)**  
**Eagle Cars & Tiger Taxis | Oct 2024 - Present | Clitheroe, UK**  
As a Data Visualization Analyst, I am responsible for designing and automating dashboards to track and analyze the performance of drivers across various metrics.  
Key Responsibilities:  
- **Weekly/Monthly Dashboards**: Created and managed dashboards that report driver performance, including key metrics such as average trip duration, number of trips, and ratings.  
- **Report Automation**: Used Power BI, Python (Seaborn), and Excel to automate the reporting process, reducing the time spent on manual reporting tasks by 50%.  
- **Data Visualization & Storytelling**: Developed intuitive visualizations that translated complex data into clear insights for stakeholders, improving decision-making.  

🛠 **Tools Used**: Power BI, Seaborn (Python), Excel  

---

### 🧠 **Data Scientist (Full-Time)**  
**WebDoc | May 2023 - Dec 2023 | Islamabad, Pakistan**  
At WebDoc, I applied data science techniques to improve data accuracy and generate insights that directly impacted decision-making processes.  
Key Responsibilities:  
- **Data Integrity**: Worked with cross-functional teams to improve the accuracy and consistency of data by 20% through cleaning and validation processes using Python, SQL, and R.  
- **Visualization & Reporting**: Created over 15 dynamic visualizations to represent complex datasets, enabling leadership teams to make data-driven decisions faster.  
- **Statistical Modeling**: Applied regression and classification models to predict trends in user behavior and optimize services.  

🛠 **Tools Used**: Python, SQL, R, Matplotlib, ggplot2  

---

### 📈 **Data Insights Analyst (Full-Time)**  
**Zones, IT Solutions | Sep 2021 - May 2023 | Islamabad, Pakistan**  
In this role, I focused on deriving actionable insights from data to improve business processes and enhance customer retention.  
Key Responsibilities:  
- **Customer Retention Strategy**: Developed and executed data-driven strategies that resulted in an 18% increase in customer retention over 12 months.  
- **Business Intelligence**: Designed and maintained Power BI dashboards that displayed real-time business performance data, helping teams make quick decisions.  
- **Cross-de


## 🎯 **Activities**  
📌 **President, Dawah Society - Salford University** _(2024)_  
📌 Organized **weekly social events** to foster student engagement.

---

## 📞 **Contact**  
📧 **Email:** your.email@example.com  
🔗 **LinkedIn:** [Your LinkedIn Profile](https://www.linkedin.com/in/your-profile)  
🐙 **GitHub:** [Your GitHub Profile](https://github.com/your-username)
