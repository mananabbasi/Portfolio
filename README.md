

# 🎯 **Data Scientist Portfolio**  
🌟 Welcome to my Data Scientist Portfolio! 🚀
A showcase of my work in data analysis, machine learning, and visualization, highlighting my ability to extract insights and build data-driven solutions.
---
# 📌 Table of Contents

- [🌟 About Me](#about-me)
- [🛠 Skills](#skills)
- [⚙ Tools & Technologies](#tools-technologies)
- [🚀 Projects](#projects)
  - [Statistical Analysis Projects with R](#statistical-analysis-projects-with-r)
  - [Advanced SQL Database Development Projects](#advanced-sql-database-development-projects)
  - [Data Mining & Machine Learning Projects in Python](#data-mining-machine-learning-projects-in-python)
  - [Classification Models using Azure ML Designer](#classification-models-using-azure-ml-designer)
  - [Databricks Projects with PySpark](#databricks-projects-with-pyspark)
  - [Power BI Dashboard Development Projects](#power-bi-dashboard-development-projects)
- [💼 Work Experience](#work-experience)
- [🎓 Education](#education)
- [🎯 Activities](#activities)
- [📞 Contact](#contact)

---

## 🌟 About Me  
<a id="-about-me"></a>  
I am a data scientist dedicated to solving complex problems using data-driven methods. Specializing in statistics, machine learning, data visualization, and big data processing, I transform raw data into valuable insights. Always eager to learn, I continuously expand my knowledge and adapt to new technologies in the field.

---


## 🛠 Skills  
<a id="-skills"></a>  
Here is a list of my key technical and soft skills.

### **Technical Skills:**  
- **Programming Languages**: Python, R, SQL  
- **Machine Learning**: Classification, Regression, Clustering, Deep Learning  
- **Big Data & Cloud**: Spark, Hadoop, AWS, GCP  
- **Data Visualization**: Power BI, Tableau, Matplotlib, Seaborn  
- **Statistical Analysis**: Hypothesis Testing, ANOVA, Regression Analysis  

### **Soft Skills:**  
- **Problem Solving**  
- **Communication**  
- **Collaboration**  
- **Adaptability**  
- **Critical Thinking**

---

## ⚙ Tools & Technologies  
<a id="-tools--technologies"></a>  
I am proficient in a range of tools and technologies that help me effectively analyze data and develop insights.

- **Programming Languages**: Python, R, SQL  
- **Libraries/Frameworks**: Pandas, NumPy, Scikit-learn, TensorFlow, PyTorch  
- **Databases**: MySQL, PostgreSQL, MongoDB  
- **Big Data & Cloud**: AWS, Azure, GCP, Hadoop, Spark  
- **Data Visualization**: Power BI, Tableau, Matplotlib, Seaborn  
- **Development Tools**: Jupyter Notebook, VS Code, Git

---
## 🚀 Projects:

1 Statistical Analysis Projects Using R:


### 🔹 **A:.Statistical Analysis & Advanced Statistics using R  
**Duration:** Sep 2024 - Dec 2025  

## **Dataset**  
[Concrete Strength Prediction](https://www.kaggle.com/datasets/ruchikakumbhar/concrete-strength-prediction)  

## **R Analysis Repository**  
[GitHub Repository](https://github.com/mananabbasi/Applied_Statistics_-_Data_Visualisation_)  

## **Objective**  
To perform statistical analysis on the dataset, uncover insights, and support data-driven decision-making by understanding relationships between variables.  

## **Process**  
1. **Data Cleaning:**  
   - Handled missing values and outliers, ensuring data consistency.  
2. **Exploratory Data Analysis (EDA):**  
   - Analyzed distributions and relationships using visualizations.  
3. **Hypothesis Testing:**  
   - Conducted t-tests and chi-square tests to validate assumptions.  
4. **Regression Analysis:**  
   - Built linear regression models and evaluated performance.  
5. **ANOVA:**  
   - Compared means across groups to identify significant differences.  
6. **Visualization:**  
   - Created visualizations using **ggplot2** for clear insights.  


## **Tools Used**  
- **R** (ggplot2, dplyr, tidyr, caret, stats, etc)  

---

## **Key Visualizations**  
1. **Libraries Used**  
   ![Libraries Used](assets/Libraries_used.png)  
2. **Numerical Variable Distribution**  
   ![Numerical Distribution](assets/Distribution_of_Numerical.png)  
3. **Categorical Variable Distribution**  
   ![Categorical Distribution](assets/Catergorical_Distribution.png)  
4. **Correlation Analysis**  
   ![Correlation Matrix](assets/Corelation.png)  
5. **Age Distribution**  
   ![Age Distribution](assets/Distribtion_off_Age.png)  
6. **Simple Linear Regression (SLR) Assumptions**  
   ![SLR Assumptions](assets/SRL_Assumptions.png)  
7. **Regression Model Results**  
   ![Regression Model](assets/RegressionModel.png)  
8. **Generalized Additive Model (GAM)**  
   ![GAM Model](assets/Gam_Model.png)  
     
## **Outcome**  
- Delivered actionable insights and statistical reports to stakeholders.  
- Created visualizations and dashboards for effective communication.  
  
### 🔹 **B.Time Series Forecasting Models in R  
**Duration:** Nov 2024 - Dec 2024  

## **Dataset**  
[Vital Statistics in the UK](https://www.ons.gov.uk/peoplepopulationandcommunity/populationandmigration/populationestimates/datasets/vitalstatisticspopulationandhealthreferencetables)  

## **Code**  
[Vital Statistics in the UK - Time Series Modelling](https://github.com/mananabbasi/Time-Series-Modelling/blob/main/Birth_time_series.R)  

## **Objective**  
To develop accurate time series forecasting models for predicting future trends, enabling stakeholders to optimize business strategies.  

## **Process**  
1. **Data Preparation:**  
   - Collected and cleaned historical time series data.  
   - Ensured stationarity using transformations (e.g., differencing).  
2. **Model Selection:**  
   - Evaluated **ARIMA**, **SARIMA**, and **ETS** models for accuracy.  
3. **Model Evaluation:**  
   - Used **RMSE** and **MAE** to measure model performance.  
   - Performed cross-validation to ensure robustness.  
4. **Visualization:**  
   - Created visualizations to compare predicted vs actual values.  

## **Tools Used**  
- **R** (forecast, tseries, ggplot2)  

---

## **Key Visualizations**  
1. **Time Series Plot**  
   ![Time Series](assets/TimeSeries.png)  
2. **Additive Model with Trend**  
   ![Additive Model](assets/Additive_model_with_increasing_or_decreasing_trend_and_no_seasonality.png)  
3. **Partial Correlogram**  
   ![Partial Correlogram](assets/partial_corelegram.png)  
4. **Forecasting Results**  
   ![Forecasting](assets/TS_Forcasting.png)  
5. **Forecast Errors**  
   ![Forecast Errors](assets/TS_Forcast_Errors.png)  

## **Outcome**  
- Provided actionable insights through thorough EDA and robust regression model evaluation.  
- Significantly improved inventory management efficiency and informed data-driven decision-making.


2 Advanced SQL Database Development Projects:


---

### 🔹 **A Hospital Database Development (Microsoft SQL Server)**  
**Duration:** Jan 2024 - Apr 2024

**Objective:**  
Designed and implemented a scalable, high-performance hospital database to manage large volumes of data.

**Process:**  
- Created ER diagrams and normalized schema.
- Optimized with indexing and automated tasks using stored procedures and triggers.

**Outcome:**  
- Fully operational, scalable database system optimized for fast queries and data integrity.

**Tools Used:**  
- **Microsoft SQL Server**, **T-SQL**

### Key Visualizations:

- **Database Diagram**  
![Database Diagram](assets/Data_Base_Diagram.png)

- **Total Appointments**  
![Appointments](assets/Appointsments.png)

- **Today's Appointments**  
![Returning Today's Appointments](assets/Returing_Todays Apointsments.png)

  3 Power BI Dashboard Development Projects

### 🔹 **A. Power BI Dashboard: Real-Time Insights by Region and Country Group**  
**Duration:** Jan 2024 - Current  
**Dataset:** [World Population Prospects 2024](https://population.un.org/wpp/)  
**Other Dashboards:** [GitHub Repository](https://github.com/mananabbasi/Dashboard-Power-bi)

**Objective:**  
Create interactive, real-time dashboards for monitoring business performance and enabling data-driven decision-making.

**Process:**  
- Integrated SQL databases, Excel files, and APIs for real-time data.  
- Designed user-friendly dashboards with slicers, filters, and advanced **DAX** measures.  
- Optimized for fast performance and real-time updates.

**Tools Used:**  
- **Power BI**, **DAX**, **SQL**

**Key Visualizations:**  
- **Final Dashboard**  
   ![Final Dashboard](assets/Final_Dashboard.png)  

**Outcome:**  
- Delivered real-time interactive dashboards for performance tracking and data-driven decisions.


4  Data Mining and Machine Learning Projects in Python

### 🔹 **A. Classification Models in Python for Banking**  
**Duration:** Sep 2024 - Present  
**Objective:**  
Developed ML models to predict client subscription to term deposits using the banking dataset.

**Dataset:**  
[Bank Marketing Dataset](https://archive.ics.uci.edu/dataset/222/bank+marketing)  
**Code:**  
- [KNN Classification](https://github.com/mananabbasi/Machine-Learning-and-Data-Mining-/blob/main/KNN%20-%20Classification%20with%20Class%20Imbalance.ipynb)  
- [Decision Tree Classification](https://github.com/mananabbasi/Machine-Learning-and-Data-Mining-/blob/main/Classification%20Decision_Tree%20with%20class%20imbalance.ipynb)

**Process:**  
- Preprocessed data and built **classification** and **clustering models** (Logistic Regression, Random Forest, SVM, K-Means, DBSCAN).  
- Evaluated models with accuracy, precision, recall, F1, and silhouette scores.  
- Hyperparameter tuning with **GridSearchCV** and **RandomizedSearchCV**.

**Outcome:**  
- Delivered accurate predictive models, uncovering customer behavior patterns.

**Tools:** Python, Scikit-learn, Pandas, Matplotlib

**Key Visualizations:**  
- **Data Exploration**  
  ![MLDM Calls](assets/MLDM_Calls.png)  
- **Model Performance**  
  ![KNN Classification](assets/KNNCLASSIFICATION.png)  
  ![Decision Tree Classification](assets/Decsiiontreeclassicifation.png)

**Actionable Recommendations:**  
- Use **Decision Tree** over KNN for better performance.  
- Focus on **call duration** (Feature 12).  
- Target **college-educated, married individuals (30-40)** in **management roles**.  
- Optimal campaign timing: **mid-month** and **summer months**.  
- Prioritize **mobile contact** and impactful first interactions.

# 🔹 **B. Customer Segmentation Using K-Means and Hierarchical Clustering on Credit Card Data**  
**Duration:** Sep 2024 - Present  

**Objective:**  
Developed ML models for customer segmentation using clustering techniques to identify distinct groups and optimize marketing strategies.

**Dataset:**  
[Credit Card Marketing Dataset](https://www.kaggle.com/datasets/arjunbhasin2013/ccdata?resource=download)

**Code:**  
- [K-Means Clustering](https://github.com/mananabbasi/Machine-Learning-and-Data-Mining-/blob/main/ClusteringK-Means.ipynb)  
- [Hierarchical Clustering](https://github.com/mananabbasi/Machine-Learning-and-Data-Mining-/blob/main/Dendogram_Clustring.ipynb)

## **Process:**  
- **Data Preparation:** Cleaned and encoded data using **Pandas**.  
- **Clustering:** Applied **K-Means** and **Hierarchical Clustering**, scaled features, and used **PCA** for dimensionality reduction.  
- **Evaluation & Optimization:** Used **Silhouette Score** and **Elbow Method** to evaluate clusters.  
- **Visualization:** Created visualizations for actionable insights.

## **Outcome:**  
- Developed scalable pipelines for real-time insights and enhanced decision-making.  

## **Tools Used:**  
- Python, Scikit-learn, Pandas, Matplotlib

## **Key Visualizations:**  
- **Correlation Analysis**  
   ![Correlation](assets/CLUstering_Corelation.png)  
- **Dendrogram**  
   ![Dendrogram](assets/Dendogram.png)  
- **K-Means Clustering**  
   ![K-Means](assets/Kmeans-Clusters.png)

## **Recommendations:**  
- **K-Means (2 Clusters):** Simple segmentation for broad targeting.  
- **Hierarchical (4 Clusters):** Detailed insights for refined marketing.  
- **CASH_ADVANCE:** Target **high users** with rewards, **low users** with education.  
- **Credit Limit:** Promote for **low usage, high limits** and **raise limits for high usage, low credit limits**.
### 🔹 **C. Sentiment Analysis and Text Classification on US McDonald's Reviews Dataset**  
**Duration:** Sep 2024 - Present  

**Objective:**  
Developed ML models to analyze sentiment and classify customer reviews from McDonald's US stores.

**Dataset:**  
[US McDonald's Stores Reviews Dataset](https://www.kaggle.com/datasets/nelgiriyewithana/mcdonalds-store-reviews)  

**Code:**  
- [Sentiment Analysis and Text Classification](https://github.com/mananabbasi/Machine-Learning-and-Data-Mining-/blob/main/Sentimental_Analysis_and_Text_Classification_on_MacDonalds_Dataset.ipynb)

## **Process:**  
- **Data Preprocessing:** Cleaned data, tokenized, lemmatized, and encoded features with **NLTK** and **Scikit-learn**.  
- **Feature Engineering:** Extracted word frequencies, n-grams, and sentiment scores using **TextBlob** and **TF-IDF**.  
- **Model Development:** Built classification models (Logistic Regression, Random Forest, SVM) and clustering models (K-Means, DBSCAN) for sentiment analysis and review grouping.

## **Outcome:**  
- Developed sentiment analysis and classification models, revealing key review patterns and customer sentiment.

## **Tools Used:**  
- Python, **Scikit-learn**, **Pandas**, **Matplotlib**, **NLTK**, **TextBlob**

## **Key Visualizations:**  
- **Sentiment Distribution**  
   ![Overall Sentiment](assets/OVerallsentiment.png)  
- **Positive Reviews**  
   ![Positive Reviews](assets/POsitivereviews.png)  
- **Negative Reviews & Word Clouds**  
   ![Negative Word Cloud](assets/Nogativeword.png)

## **Recommendations:**  
- **Text Classification:** Use models for real-time customer sentiment analysis and response.  
- **Sentiment Insights:** Focus on improving food quality and service speed at underperforming stores (e.g., Miami Beach).

5 : Classification Models on Azure ML Designer
### 🔹 **A. Classification Models on Azure ML Designer**  
**Duration:** Sep 2024 - Present  

**Dataset:**  
[Banking Dataset](https://archive.ics.uci.edu/dataset/222/bank+marketing)

**Code:**  
[Azure ML Designer Code](https://github.com/mananabbasi/Azure-ML-Designer)

## **Process:**  
1. **Upload & Clean Data:** Import dataset, handle missing values, and split data into training and testing sets.  
2. **Model Selection & Training:** Choose classification algorithms (e.g., Logistic Regression, Decision Tree, SVM), and train the model.  
3. **Model Evaluation:** Evaluate using accuracy, precision, and recall.  
4. **Hyperparameter Tuning & Deployment:** Optionally tune the model and deploy it for real-time predictions.

## **Outcome:**  
- Built accurate classification models for client subscription prediction, enabling targeted marketing strategies.

## **Tools Used:**  
- **Azure ML Studio**, **Azure ML Designer**, **Logistic Regression**, **Decision Tree**, **Random Forest**, **SVM**, **Hyperparameter Tuning**

## **Key Visualizations:**  
- **Model Comparison**:  
   ![Decision Tree and Random Forest](assets/DecisiontreeandRandomForest.png)  
- **Model Performance**:  
   ![Logistic Regression](assets/LogisticRegression.png)  
   ![Decision Tree Evaluation](assets/DecisiontreeEvaluation.png)

  6 Databricks Projects with PySpark Functions

### 🔹 **A. Databricks Projects Using PySpark (RDD, DataFrames, and SQL)**  
**Duration:** Jan 2024 - Present  

**Objective:**  
Efficiently process and analyze large-scale datasets using **PySpark** on **Databricks**, creating optimized data pipelines for big data challenges.

**Datasets:**  
- [Clinical Dataset](https://clinicaltrials.gov/data-api/about-api/csv-download)  
- [Pharma Sales Dataset](https://www.kaggle.com/datasets/milanzdravkovic/pharma-sales-data)  

**Code:**  
[Code Repository](https://github.com/mananabbasi/Data-Science-Complete-Project-using-Big-Data-Tools-Techniques-)

## **Process:**  
1. **Data Import & Transformation:**  
   - Used **RDDs** and **DataFrames** to load and clean large datasets.  
   - Applied **Spark SQL** for data aggregation and transformation.  
   
2. **Optimization:**  
   - Optimized pipelines with **partitioning, caching**, and **parallel processing**.  
   
3. **Big Data Processing:**  
   - Processed large datasets for real-time insights.

4. **Visualization:**  
   - Used **Databricks Notebooks** to visualize data and generate reports.

## **Outcome:**  
- Developed scalable pipelines for large-scale data processing, enabling real-time analytics.

## **Tools Used:**  
- **PySpark** (RDDs, DataFrames, Spark SQL), **Databricks**, **Python**, **Databricks Notebooks**

### 🔹 **B. Steam Data Analysis: Visualization & ALS Evaluation in Databricks**  
**📅 Duration:** Jan 2024 - Present  

**Objective:**  
Analyze large-scale Steam datasets using **PySpark** on **Databricks**, with data visualization and **ALS (Alternating Least Squares)** for recommendation system evaluation.

**Dataset:**  
- 🎮 [Steam Games Dataset](https://github.com/win7guru/steam-dataset-2024/blob/main/games.zip)  

**Code Repository:**  
🔗 [GitHub: Data Analysis, Visualization & ALS Evaluation](https://github.com/mananabbasi/Data-Analysis-Visualization-ALS-Evaluation-in-Databricks)

## **Process:**  
1. **Data Import & Cleaning:** Loaded and cleaned Steam dataset using **PySpark**.  
2. **EDA & Visualization:** Visualized game trends and pricing with **Matplotlib** and **Seaborn**.  
3. **ALS Model:** Built and tuned a recommendation system using **ALS**, optimized with RMSE.  
4. **Predictions & Recommendations:** Generated personalized game suggestions.  

## **Outcome:**  
- Developed scalable pipelines for real-time analytics and insights.

## **Tools Used:**  
- **PySpark** (RDDs, DataFrames, Spark SQL), **Databricks**, **Python**

## **Key Visualizations:**  
- **Top 10 Recommendations per User**  
  ![Top 10 Recommendations](assets/Top10.png)

## 💼 Work Experience  
<a id="-work-experience"></a>  
I have gained hands-on experience in various data science roles, where I applied my skills to solve real-world business challenges.

### **Data Visualization Analyst (Part-Time)**  
**Eagle Cars & Tiger Taxis | Oct 2024 - Present | Clitheroe, UK**  
- Created weekly and monthly dashboards to report driver performance.  
- Automated reporting processes, reducing manual reporting time by 50%.  
- Developed visualizations that improved decision-making for stakeholders.

### **Data Scientist (Full-Time)**  
**WebDoc | May 2023 - Dec 2023 | Islamabad, Pakistan**  
- Improved data accuracy by 20% through data cleaning and validation.  
- Created over 15 dynamic visualizations to represent complex datasets.  
- Applied regression and classification models to predict user behavior.

### **Data Insights Analyst (Full-Time)**  
**Zones, IT Solutions | Sep 2021 - May 2023 | Islamabad, Pakistan**  
- Developed data-driven strategies that increased customer retention by 18%.  
- Designed and maintained Power BI dashboards for real-time performance tracking.  
- Collaborated with cross-functional teams to design reports for business decisions.

---

## 🎓 Education  
<a id="-education"></a>  
Here’s my academic background that laid the foundation for my career in data science.

### **M.S. in Data Science** _(Expected May 2025)_  
**University of Salford, UK**  
- Coursework: Machine Learning, Big Data Analytics, NLP, Deep Learning

### **B.S. in Software Engineering** _(Graduated May 2022)_  
**Bahria University, Pakistan**  
- Coursework: AI, Data Mining, Web Development, Database Systems

---

## 🎯 Activities  
<a id="-activities"></a>  
In addition to my professional and academic pursuits, I am actively involved in extracurricular activities.

### **President, Dawah Society - Salford University** _(2024)_  
- Organized weekly social events to foster student engagement and unity.

---

## 🔧 How to Use This Repository  
<a id="-how-to-use-this-repository"></a>  
Clone this repository to explore my projects and codebase:  
```bash
git clone https://github.com/your-username/data-scientist-portfolio.git  
cd data-scientist-portfolio

## 📞 Contact
<a id="-contact"></a>
You can get in touch with me through the following channels:

📧 Email: mananw25@gmail.com
🔗 LinkedIn: [ Linkedin Profile](https://www.linkedin.com/in/abdul-manan-4a685926a/)
🐙 GitHub: [ GitHub Profile](https://github.com/mananabbasi)---

